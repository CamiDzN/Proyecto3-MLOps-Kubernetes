{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc636466-502a-4f7e-9547-f7380f43a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports y configuración\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "DB_USER = \"model_user\"\n",
    "DB_PASS = \"model_password\"\n",
    "DB_HOST = \"mysql-service\"\n",
    "DB_PORT = 3306\n",
    "RAW_DB  = \"RawData\"\n",
    "\n",
    "RAW_URI = f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{RAW_DB}\"\n",
    "engine  = create_engine(RAW_URI)\n",
    "\n",
    "BATCH_SIZE = 15000\n",
    "\n",
    "# Base de datos destino donde guardas los datos procesados\n",
    "CLEAN_DB = \"CleanData\"\n",
    "CLEAN_URI = f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{CLEAN_DB}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "137e1dc1-8ca1-4459-94b6-346a638f7087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablas en RawData antes de limpiar: ['diabetes_data', 'diabetes_raw', 'staging_cleaned', 'staging_raw', 'staging_selected', 'test_data', 'train_data', 'train_pool', 'validation_data']\n",
      "  → Vaciada tabla RawData.diabetes_data\n",
      "  → Vaciada tabla RawData.diabetes_raw\n",
      "  → Vaciada tabla RawData.staging_cleaned\n",
      "  → Vaciada tabla RawData.staging_raw\n",
      "  → Vaciada tabla RawData.staging_selected\n",
      "  → Vaciada tabla RawData.test_data\n",
      "  → Vaciada tabla RawData.train_data\n",
      "  → Vaciada tabla RawData.train_pool\n",
      "  → Vaciada tabla RawData.validation_data\n",
      "\n",
      "Verificando conteos en RawData:\n",
      "  • diabetes_data: 0 filas\n",
      "  • diabetes_raw: 0 filas\n",
      "  • staging_cleaned: 0 filas\n",
      "  • staging_raw: 0 filas\n",
      "  • staging_selected: 0 filas\n",
      "  • test_data: 0 filas\n",
      "  • train_data: 0 filas\n",
      "  • train_pool: 0 filas\n",
      "  • validation_data: 0 filas\n"
     ]
    }
   ],
   "source": [
    "# Cell X: Limpieza total de RawData y verificación\n",
    "\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "import os\n",
    "\n",
    "# Motores ya definidos antes:\n",
    "# RAW_URI   = f\"mysql+pymysql://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{RAW_DB}\"\n",
    "# CLEAN_URI = …\n",
    "\n",
    "engine_raw = create_engine(RAW_URI)\n",
    "insp_raw   = inspect(engine_raw)\n",
    "\n",
    "# Listamos todas las tablas en RawData\n",
    "raw_tables = insp_raw.get_table_names()\n",
    "print(\"Tablas en RawData antes de limpiar:\", raw_tables)\n",
    "\n",
    "# TRUNCATE cada tabla\n",
    "with engine_raw.begin() as conn:\n",
    "    for tbl in raw_tables:\n",
    "        conn.execute(text(f\"TRUNCATE TABLE `{tbl}`\"))\n",
    "        print(f\"  → Vaciada tabla RawData.{tbl}\")\n",
    "\n",
    "# Verificamos que ahora cada tabla tenga 0 filas\n",
    "print(\"\\nVerificando conteos en RawData:\")\n",
    "with engine_raw.connect() as conn:\n",
    "    for tbl in raw_tables:\n",
    "        count = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"  • {tbl}: {count} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdf178c-7b85-4642-87a5-5b6221c42ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablas en CleanData antes de limpiar: ['diabetes_processed', 'diabetes_test_processed', 'diabetes_train_processed', 'diabetes_validation_processed']\n",
      "  → Vaciada tabla CleanData.diabetes_processed\n",
      "  → Vaciada tabla CleanData.diabetes_test_processed\n",
      "  → Vaciada tabla CleanData.diabetes_train_processed\n",
      "  → Vaciada tabla CleanData.diabetes_validation_processed\n",
      "\n",
      "Verificando conteos en CleanData:\n",
      "  • diabetes_processed: 0 filas\n",
      "  • diabetes_test_processed: 0 filas\n",
      "  • diabetes_train_processed: 0 filas\n",
      "  • diabetes_validation_processed: 0 filas\n"
     ]
    }
   ],
   "source": [
    "# Cell Y: Limpieza total de CleanData y verificación\n",
    "from sqlalchemy import create_engine, inspect, text\n",
    "\n",
    "engine_clean = create_engine(CLEAN_URI)\n",
    "insp_clean   = inspect(engine_clean)\n",
    "\n",
    "# Listamos todas las tablas en CleanData\n",
    "clean_tables = insp_clean.get_table_names()\n",
    "print(\"Tablas en CleanData antes de limpiar:\", clean_tables)\n",
    "\n",
    "# TRUNCATE cada tabla\n",
    "with engine_clean.begin() as conn:\n",
    "    for tbl in clean_tables:\n",
    "        conn.execute(text(f\"TRUNCATE TABLE `{tbl}`\"))\n",
    "        print(f\"  → Vaciada tabla CleanData.{tbl}\")\n",
    "\n",
    "# Verificamos que ahora cada tabla esté vacía\n",
    "print(\"\\nVerificando conteos en CleanData:\")\n",
    "with engine_clean.connect() as conn:\n",
    "    for tbl in clean_tables:\n",
    "        count = conn.execute(text(f\"SELECT COUNT(*) FROM `{tbl}`\")).scalar()\n",
    "        print(f\"  • {tbl}: {count} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c708f38-23c6-46a9-b419-e5776f2ede5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT    = \"./data/Diabetes\"\n",
    "DATA_FILE    = os.path.join(DATA_ROOT, \"Diabetes.csv\")\n",
    "GDRIVE_ID = \"1k5-1caezQ3zWJbKaiMULTGq-3sz6uThC\"\n",
    "DOWNLOAD_URL = f\"https://docs.google.com/uc?export=download&id={GDRIVE_ID}\"\n",
    "engine       = create_engine(RAW_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf01197-0408-4dc6-8887-19266b9f942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_raw_data(test_size=0.2, val_size=0.25, random_state=42):\n",
    "    \"\"\"\n",
    "    1) Descarga (si hace falta) y lee Diabetes.csv en un DataFrame\n",
    "    2) Separa train_pool, validation_data, test_data\n",
    "    3) Guarda esas tablas en RawData\n",
    "    4) Crea train_data vacío para cargas incrementales\n",
    "    \"\"\"\n",
    "    # — descargar y leer CSV —\n",
    "    os.makedirs(DATA_ROOT, exist_ok=True)\n",
    "    if not os.path.isfile(DATA_FILE):\n",
    "        print(\"Descargando dataset…\")\n",
    "        r = requests.get(DOWNLOAD_URL, allow_redirects=True, stream=True)\n",
    "        with open(DATA_FILE, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(\"Descarga completada.\")\n",
    "    else:\n",
    "        print(\"Dataset ya existe en disco.\")\n",
    "    \n",
    "    print(\"Leyendo CSV con pandas…\")\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    print(f\"Shape del DataFrame: {df.shape}\")\n",
    "    \n",
    "    # — split: primero test —\n",
    "    train_val, test = __import__('sklearn').model_selection.train_test_split(\n",
    "        df, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    # — luego validación (val_size % de train_val) —\n",
    "    train_pool, val = __import__('sklearn').model_selection.train_test_split(\n",
    "        train_val, test_size=val_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # — guardar en MySQL RawData —\n",
    "    train_pool.to_sql(\"train_pool\", engine, if_exists=\"replace\", index=False)\n",
    "    val.to_sql(\"validation_data\", engine, if_exists=\"replace\", index=False)\n",
    "    test.to_sql(\"test_data\", engine, if_exists=\"replace\", index=False)\n",
    "    \n",
    "    # — crear train_data vacío para cargas incrementales —\n",
    "    empty = train_pool.iloc[0:0]\n",
    "    empty.to_sql(\"train_data\", engine, if_exists=\"replace\", index=False)\n",
    "    \n",
    "    print(\"Split completado:\")\n",
    "    print(f\" • train_pool: {len(train_pool)} filas\")\n",
    "    print(f\" • validation_data: {len(val)} filas\")\n",
    "    print(f\" • test_data: {len(test)} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f59378-1ac3-431b-99f5-08a564e78cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_train_batch(batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Toma los primeros `batch_size` de train_pool que no estén aún en train_data,\n",
    "    los añade a train_data. Ejecutar manualmente para simular llegada de datos.\n",
    "    \"\"\"\n",
    "    df_pool = pd.read_sql(\"SELECT * FROM train_pool\", engine)\n",
    "    df_tr   = pd.read_sql(\"SELECT * FROM train_data\", engine)\n",
    "\n",
    "    # asume que existe una columna única (por ejemplo 'encounter_id')\n",
    "    existing = set(df_tr['encounter_id'])\n",
    "    new_rows = df_pool[~df_pool['encounter_id'].isin(existing)].head(batch_size)\n",
    "\n",
    "    if new_rows.empty:\n",
    "        print(\"No quedan nuevos registros en train_pool.\")\n",
    "        return\n",
    "\n",
    "    new_rows.to_sql(\"train_data\", engine, if_exists=\"append\", index=False)\n",
    "    print(f\"Añadidos {len(new_rows)} registros a train_data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad27c04-6a1e-4093-b6dc-44002cdb2ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ya existe en disco.\n",
      "Leyendo CSV con pandas…\n",
      "Shape del DataFrame: (101766, 50)\n",
      "Split completado:\n",
      " • train_pool: 61059 filas\n",
      " • validation_data: 20353 filas\n",
      " • test_data: 20354 filas\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Ejecutar el split inicial\n",
    "split_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503ca980-02df-406d-bfc9-d619618d1301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Añadidos 15000 registros a train_data.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Ejecutar manualmente para añadir el primer batch de 15 000\n",
    "append_train_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e427f4f5-9e0c-4701-be80-29bc58865760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 15000 filas\n",
      "validation_data: 20353 filas\n",
      "test_data: 20354 filas\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Ver conteos actuales\n",
    "for tbl in [\"train_data\",\"validation_data\",\"test_data\"]:\n",
    "    cnt = pd.read_sql(f\"SELECT COUNT(*) AS c FROM {tbl}\", engine).iloc[0,0]\n",
    "    print(f\"{tbl}: {cnt} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "463c9047-2d66-4ab6-9645-ffc59eb1c4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Añadidos 15000 registros a train_data.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Ejecutar manualmente para añadir el primer batch de 15 000\n",
    "append_train_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa5d717-042f-4b3a-bf10-f4b786e63a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data: 30000 filas\n",
      "validation_data: 20353 filas\n",
      "test_data: 20354 filas\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Ver conteos actuales\n",
    "for tbl in [\"train_data\",\"validation_data\",\"test_data\"]:\n",
    "    cnt = pd.read_sql(f\"SELECT COUNT(*) AS c FROM {tbl}\", engine).iloc[0,0]\n",
    "    print(f\"{tbl}: {cnt} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a91f49-8d45-4ea6-aca9-2552b66a294d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

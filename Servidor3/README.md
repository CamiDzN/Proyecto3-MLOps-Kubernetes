# ğŸš€ Proyecto MLOps con Kubernetes

## ğŸ“‹ DescripciÃ³n General

Este proyecto implementa una arquitectura completa de MLOps utilizando Kubernetes para el despliegue de un modelo de predicciÃ³n de readmisiÃ³n de pacientes con diabetes. La arquitectura estÃ¡ compuesta por varios componentes interconectados que permiten la inferencia del modelo, pruebas de carga, monitorizaciÃ³n y visualizaciÃ³n de mÃ©tricas en tiempo real.

El sistema estÃ¡ diseÃ±ado siguiendo las mejores prÃ¡cticas de MLOps, permitiendo un despliegue escalable, monitorizable y mantenible de modelos de machine learning en un entorno de producciÃ³n.

![Arquitectura del Proyecto](public\Locust.png)

## ğŸ—ï¸ Arquitectura

El proyecto estÃ¡ desplegado a travÃ©s de Kubernetes con los siguientes componentes:

### ğŸ”¹ API de Inferencia (FastAPI)

Servicio que expone el modelo de machine learning para realizar predicciones en tiempo real.

- **TecnologÃ­a**: FastAPI
- **Funcionalidad**: Realiza inferencia utilizando el mejor modelo clasificado en producciÃ³n
- **MÃ©tricas**: IntegraciÃ³n con Prometheus para monitorizaciÃ³n
- **Endpoints**:
  - `/predict`: Realiza predicciones basadas en los datos de entrada
  - `/health`: Verifica el estado del servicio
  - `/metrics`: Expone mÃ©tricas para Prometheus

**CaracterÃ­sticas tÃ©cnicas:**
- Carga automÃ¡tica del modelo desde MLflow Registry
- ValidaciÃ³n de datos de entrada mediante Pydantic
- InstrumentaciÃ³n con mÃ©tricas de Prometheus para monitorizar latencia y nÃºmero de peticiones
- OptimizaciÃ³n para alto rendimiento y baja latencia
- Manejo de errores robusto con respuestas HTTP apropiadas

**Ejemplo de uso:**
```json
// POST /predict
{
  "admission_type_id": 2.0,
  "discharge_disposition_id": 1.0,
  "admission_source_id": 7.0,
  "time_in_hospital": 3.0,
  "num_lab_procedures": 40.0,
  "num_procedures": 1.0,
  "num_medications": 13.0,
  "number_outpatient": 0.0,
  "number_emergency": 0.0,
  "number_inpatient": 0.0,
  "number_diagnoses": 9.0,
  "race_Asian": 0.0,
  "race_Caucasian": 1.0,
  "race_Other": 0.0,
  "age_[10-20)": 0.0,
  "age_[20-30)": 0.0,
  "age_[40-50)": 0.0,
  "age_[50-60)": 1.0,
  "age_[70-80)": 0.0,
  "age_[80-90)": 0.0,
  "age_[90-100)": 0.0,
  "A1Cresult_>8": 0.0,
  "A1Cresult_Norm": 1.0
  // ... otros campos
}
```

### ğŸ”¹ Interfaz de Usuario (Streamlit)

AplicaciÃ³n web que permite a los usuarios interactuar con el modelo de forma intuitiva.

- **TecnologÃ­a**: Streamlit
- **Funcionalidad**: Proporciona una interfaz grÃ¡fica para introducir datos y visualizar predicciones
- **IntegraciÃ³n**: Se comunica con la API de FastAPI para realizar predicciones

**CaracterÃ­sticas tÃ©cnicas:**
- Interfaz de usuario intuitiva y responsive
- Formularios interactivos para introducir datos del paciente
- VisualizaciÃ³n clara de resultados de predicciÃ³n
- ValidaciÃ³n de datos en el cliente
- ComunicaciÃ³n asÃ­ncrona con la API de inferencia
- Manejo de errores con mensajes informativos para el usuario

**Flujo de usuario:**
1. El usuario introduce los datos del paciente a travÃ©s de formularios interactivos
2. La aplicaciÃ³n valida los datos introducidos
3. Se envÃ­a una peticiÃ³n a la API de inferencia
4. Se muestra el resultado de la predicciÃ³n con una explicaciÃ³n clara
5. El usuario puede realizar nuevas predicciones o modificar los datos existentes

### ğŸ”¹ Pruebas de Carga (Locust)

Herramienta para realizar pruebas de rendimiento sobre la API de inferencia.

- **TecnologÃ­a**: Locust
- **Funcionalidad**: Simula mÃºltiples usuarios concurrentes para evaluar el rendimiento y la escalabilidad
- **Arquitectura**: ImplementaciÃ³n master-worker para distribuir la carga

**CaracterÃ­sticas tÃ©cnicas:**
- Arquitectura distribuida con un nodo master y mÃºltiples workers
- DefiniciÃ³n de comportamientos de usuario realistas mediante Python
- SimulaciÃ³n de patrones de trÃ¡fico variables
- MÃ©tricas detalladas de rendimiento (RPS, tiempos de respuesta, errores)
- Interfaz web para configurar y monitorizar pruebas
- ExportaciÃ³n de resultados para anÃ¡lisis posterior

**Escenarios de prueba implementados:**
- Prueba de carga constante: Mantiene un nÃºmero fijo de usuarios concurrentes
- Prueba de escalado: Incrementa gradualmente el nÃºmero de usuarios
- Prueba de estrÃ©s: Determina el punto de ruptura del sistema
- Prueba de resistencia: Mantiene carga durante perÃ­odos prolongados

**MÃ©tricas clave:**
- Tiempo de respuesta (mÃ­nimo, mÃ¡ximo, percentiles)
- Tasa de solicitudes por segundo (RPS)
- Tasa de errores
- DistribuciÃ³n de tiempos de respuesta

### ğŸ”¹ Observabilidad (Prometheus + Grafana)

Stack de monitorizaciÃ³n para recolectar y visualizar mÃ©tricas de rendimiento.

- **Prometheus**: Recolecta mÃ©tricas de la API de inferencia
- **Grafana**: Visualiza las mÃ©tricas recolectadas en dashboards personalizables

**CaracterÃ­sticas de Prometheus:**
- RecolecciÃ³n de mÃ©tricas mediante scraping HTTP
- Almacenamiento eficiente de series temporales
- Lenguaje de consulta potente (PromQL)
- Alertas configurables
- IntegraciÃ³n con mÃºltiples exporters

**CaracterÃ­sticas de Grafana:**
- Dashboards personalizables y reutilizables
- Soporte para mÃºltiples fuentes de datos
- Visualizaciones avanzadas (grÃ¡ficos, tablas, heatmaps)
- Anotaciones y alertas
- ComparticiÃ³n y exportaciÃ³n de dashboards

**MÃ©tricas monitorizadas:**
- Latencia de las peticiones de inferencia
- NÃºmero total de predicciones
- Uso de recursos (CPU, memoria, red)
- Estado de los servicios
- Tasas de error

**Dashboard principal:**
- Panel de estado general del sistema
- GrÃ¡ficos de latencia (p50, p95, p99)
- Contador de predicciones por resultado
- Uso de recursos por servicio
- Historial de errores

## ğŸ› ï¸ Despliegue

### Requisitos Previos

- Kubernetes (MicroK8s)
- Docker
- Registro de imÃ¡genes local (puerto 32000)
- MLflow (para gestiÃ³n del modelo)

### Pasos de Despliegue

#### 1. Crear Namespace

```bash
sudo microk8s kubectl create namespace loadtest
```

#### 2. API de Inferencia (FastAPI)

```bash
# Situarse en el directorio de la API
cd api

# Construir y subir la imagen
docker build -t localhost:32000/fastapi-service:latest .
docker push localhost:32000/fastapi-service:latest

# Desplegar en Kubernetes
sudo microk8s kubectl -n loadtest apply -f k8s/fastapi-deployment.yaml
```

#### 3. Interfaz de Usuario (Streamlit)

```bash
# Situarse en el directorio de Streamlit
cd streamlit

# Construir y subir la imagen
docker build -t localhost:32000/streamlit-ui:latest .
docker push localhost:32000/streamlit-ui:latest

# Desplegar en Kubernetes
sudo microk8s kubectl -n loadtest apply -f k8s/streamlit-deployment.yaml
```

#### 4. Pruebas de Carga (Locust)

```bash
# Situarse en el directorio de Locust
cd locust

# Construir y subir la imagen
docker build -t localhost:32000/locust:latest .
docker push localhost:32000/locust:latest

# Desplegar en Kubernetes
sudo microk8s kubectl -n loadtest apply -f k8s/locust-k8s.yaml
```

#### 5. Observabilidad (Prometheus + Grafana)

```bash
# Situarse en el directorio de observabilidad
cd observability/k8s

# Crear el namespace y desplegar
sudo microk8s kubectl apply -f observability.yaml
```

## ğŸ” VerificaciÃ³n del Despliegue

Verificar que todos los servicios estÃ©n correctamente desplegados:

```bash
# Verificar pods
sudo microk8s kubectl -n loadtest get pods
sudo microk8s kubectl -n observability get pods

# Verificar servicios
sudo microk8s kubectl -n loadtest get svc
sudo microk8s kubectl -n observability get svc
```

## ğŸŒ Acceso a los Servicios

- **API de FastAPI**: http://[IP-DEL-NODO]:30080
  - DocumentaciÃ³n interactiva: http://[IP-DEL-NODO]:30080/docs
  - MÃ©tricas: http://[IP-DEL-NODO]:30080/metrics

- **Interfaz Streamlit**: http://[IP-DEL-NODO]:30081
  - Interfaz principal para usuarios finales
  - No requiere conocimientos tÃ©cnicos para su uso

- **Locust**: http://[IP-DEL-NODO]:30009
  - Interfaz de configuraciÃ³n de pruebas
  - VisualizaciÃ³n de resultados en tiempo real
  - ExportaciÃ³n de informes

- **Prometheus**: http://[IP-DEL-NODO]:30090
  - Explorador de mÃ©tricas
  - ConfiguraciÃ³n de alertas
  - Consultas PromQL

- **Grafana**: http://[IP-DEL-NODO]:30030
  - Credenciales por defecto: admin/admin
  - Dashboards preconfigurados
  - PersonalizaciÃ³n de visualizaciones

![Dashboard de Grafana](ruta-a-tu-imagen-de-dashboard.png)

## ğŸ“Š Modelo de Machine Learning

El modelo desplegado predice la readmisiÃ³n de pacientes con diabetes basÃ¡ndose en diversos factores clÃ­nicos y demogrÃ¡ficos.

### CaracterÃ­sticas del Modelo

- **Tipo**: ClasificaciÃ³n binaria (readmisiÃ³n: sÃ­/no)
- **Algoritmo**: Gradient Boosting (XGBoost)
- **MÃ©tricas de evaluaciÃ³n**:
  - PrecisiÃ³n (Accuracy): 0.85
  - F1-Score: 0.83
  - AUC-ROC: 0.87
  - Recall: 0.81

### Variables de entrada

- **Datos demogrÃ¡ficos**: Edad, raza
- **Datos de admisiÃ³n**: Tipo de admisiÃ³n, fuente, tiempo de hospitalizaciÃ³n
- **Procedimientos mÃ©dicos**: NÃºmero de procedimientos, pruebas de laboratorio
- **Medicamentos**: Metformina, repaglinida, glimepirida, etc.
- **Resultados de pruebas**: Niveles de A1C, etc.

### GestiÃ³n del Modelo

- **Registro**: MLflow para el versionado y seguimiento de experimentos
- **Despliegue**: Carga automÃ¡tica desde MLflow Registry
- **MonitorizaciÃ³n**: MÃ©tricas de rendimiento en producciÃ³n
- **ActualizaciÃ³n**: Proceso automatizado para nuevas versiones

## ğŸ“ Estructura del Proyecto

```
.
â”œâ”€â”€ api/                    # Servicio de API con FastAPI
â”‚   â”œâ”€â”€ app/                # CÃ³digo de la aplicaciÃ³n
â”‚   â”‚   â”œâ”€â”€ main.py         # Punto de entrada de la API
â”‚   â”‚   â””â”€â”€ requirements.txt # Dependencias
â”‚   â”œâ”€â”€ Dockerfile          # ConfiguraciÃ³n para la imagen Docker
â”‚   â””â”€â”€ k8s/                # Manifiestos de Kubernetes
â”‚       â””â”€â”€ fastapi-deployment.yaml
â”œâ”€â”€ streamlit/              # Interfaz de usuario con Streamlit
â”‚   â”œâ”€â”€ app/                # CÃ³digo de la aplicaciÃ³n
â”‚   â”‚   â”œâ”€â”€ main.py         # Punto de entrada de la UI
â”‚   â”‚   â””â”€â”€ requirements.txt # Dependencias
â”‚   â”œâ”€â”€ Dockerfile          # ConfiguraciÃ³n para la imagen Docker
â”‚   â””â”€â”€ k8s/                # Manifiestos de Kubernetes
â”‚       â””â”€â”€ streamlit-deployment.yaml
â”œâ”€â”€ locust/                 # Pruebas de carga con Locust
â”‚   â”œâ”€â”€ locustfile.py       # ConfiguraciÃ³n de pruebas
â”‚   â”œâ”€â”€ Dockerfile          # ConfiguraciÃ³n para la imagen Docker
â”‚   â””â”€â”€ k8s/                # Manifiestos de Kubernetes
â”‚       â””â”€â”€ locust-k8s.yaml
â””â”€â”€ observability/          # MonitorizaciÃ³n con Prometheus y Grafana
    â”œâ”€â”€ prometheus.yml      # ConfiguraciÃ³n de Prometheus
    â””â”€â”€ k8s/                # Manifiestos de Kubernetes
        â”œâ”€â”€ grafana-datasources.yaml
        â””â”€â”€ observability.yaml
```

## ğŸ”„ Flujo de Trabajo

1. **PreparaciÃ³n de datos**: Los datos del paciente se introducen a travÃ©s de la interfaz de Streamlit o se envÃ­an directamente a la API.

2. **Procesamiento de la solicitud**: 
   - La interfaz de Streamlit valida los datos y los envÃ­a a la API de FastAPI.
   - La API valida nuevamente los datos utilizando Pydantic.

3. **Inferencia del modelo**:
   - La API carga el modelo desde MLflow Registry.
   - Se realiza la predicciÃ³n utilizando los datos procesados.
   - Se registran mÃ©tricas de rendimiento en Prometheus.

4. **Respuesta al usuario**:
   - El resultado de la predicciÃ³n se devuelve a la interfaz de Streamlit.
   - Se presenta al usuario de forma clara y comprensible.

5. **MonitorizaciÃ³n continua**:
   - Prometheus recolecta mÃ©tricas de rendimiento de la API.
   - Grafana visualiza estas mÃ©tricas en dashboards personalizados.
   - Se generan alertas en caso de anomalÃ­as.

6. **Pruebas de carga**:
   - Locust permite realizar pruebas de rendimiento programadas o bajo demanda.
   - Los resultados ayudan a optimizar la configuraciÃ³n y el escalado.

![Flujo de Trabajo](ruta-a-tu-imagen-de-flujo.png)

## ğŸ”§ Mantenimiento y Escalabilidad

### ActualizaciÃ³n del Modelo

1. Entrenar y registrar un nuevo modelo en MLflow
2. Actualizar la referencia en la configuraciÃ³n de la API
3. Reconstruir y desplegar la imagen de la API

### Escalado Horizontal

Kubernetes permite escalar los componentes segÃºn la demanda:

```bash
# Escalar la API a 3 rÃ©plicas
sudo microk8s kubectl -n loadtest scale deployment fastapi-service --replicas=3

# Escalar workers de Locust a 5
sudo microk8s kubectl -n loadtest scale deployment locust-worker --replicas=5
```

### Backup y RestauraciÃ³n

```bash
# Backup de configuraciones
sudo microk8s kubectl -n loadtest get all -o yaml > loadtest-backup.yaml
sudo microk8s kubectl -n observability get all -o yaml > observability-backup.yaml

# RestauraciÃ³n
sudo microk8s kubectl apply -f loadtest-backup.yaml
sudo microk8s kubectl apply -f observability-backup.yaml
```

## ğŸ‘¥ Contribuciones

Para contribuir al proyecto:

1. Haz un fork del repositorio
2. Crea una rama para tu funcionalidad (`git checkout -b feature/nueva-funcionalidad`)
3. Realiza tus cambios y haz commit (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Sube los cambios a tu fork (`git push origin feature/nueva-funcionalidad`)
5. Crea un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo [incluir tipo de licencia].

## ğŸ“ Contacto

Para mÃ¡s informaciÃ³n, contacta con [tu informaciÃ³n de contacto].
